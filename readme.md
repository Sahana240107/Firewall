# ğŸ›¡ï¸ PrivacyShield â€” AI Privacy Firewall

Automatically detects and redacts PII from text, images, audio, and documents before sharing.

---

## ğŸ—ï¸ Architecture

```
Input (any format)
      â†“
Layer 1: Regex          â†’ catches credit cards, Aadhaar, PAN, phone, email instantly
      â†“ (if missed)
Layer 2: DistilBERT     â†’ catches contextual PII, runs 100% locally
      â†“ (if uncertain)
Layer 3: Gemini API     â†’ fallback only, fired when layers 1+2 both pass
      â†“
Redaction Engine
      â†“
Human Review â†’ Export
```

---

## âš¡ Quick Start

### 1. Clone the repo
```bash
git clone https://github.com/YOUR_USERNAME/privacy-firewall
cd privacy-firewall
```

### 2. Create and activate virtual environment
```bash
python -m venv venv

# Windows
venv\Scripts\activate

# Mac/Linux
source venv/bin/activate
```

### 3. Install dependencies
```bash
pip install -r requirements.txt
```

### 4. Add your Gemini API key
Create a `.env` file in the root:
```
GEMINI_API_KEY=your_key_here
```
Get free key from: https://aistudio.google.com

### 5. Run the server
```bash
python main.py
```

Server runs at: http://localhost:8000
API docs at:    http://localhost:8000/docs

> **Note:** The ML model will auto-download from HuggingFace on first run.
> This takes ~1 minute. After that it's cached locally.

---

## ğŸ“ Folder Structure

```
privacy-firewall/
â”œâ”€â”€ ml/
â”‚   â”œâ”€â”€ model/              â† auto downloaded from HuggingFace
â”‚   â”œâ”€â”€ predict.py          â† DistilBERT inference
â”‚   â””â”€â”€ train.py            â† model training (already done)
â”œâ”€â”€ text_engine/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ layer1_regex.py     â† regex PII detection
â”‚   â”œâ”€â”€ layer2_bert.py      â† DistilBERT wrapper
â”‚   â”œâ”€â”€ layer3_gemini.py    â† Gemini API fallback
â”‚   â””â”€â”€ pipeline.py         â† combines all 3 layers
â”œâ”€â”€ adapters/
â”‚   â”œâ”€â”€ image_adapter.py    â† for image friend's OCR output
â”‚   â”œâ”€â”€ docs_adapter.py     â† for docs friend's output
â”‚   â””â”€â”€ audio_adapter.py    â† for audio friend's output
â”œâ”€â”€ main.py                 â† FastAPI server
â”œâ”€â”€ test_pipeline.py        â† run tests
â”œâ”€â”€ requirements.txt
â””â”€â”€ .env                    â† NOT pushed to github (add your key here)
```

---

## ğŸ”Œ API Endpoints

| Endpoint | Method | Who Uses It |
|---|---|---|
| `/api/scan/text` | POST | Direct text input |
| `/api/scan/image` | POST | Image friend (after OCR) |
| `/api/scan/docs` | POST | Docs friend (after PDF parse) |
| `/api/scan/audio` | POST | Audio friend (after Whisper) |
| `/api/scan/video` | POST | Video friend (after frame OCR) |
| `/health` | GET | Check server status |

---

## ğŸ“¨ How Friends Connect Their Work

Every friend sends their extracted text to their endpoint:

```python
import requests

result = requests.post("http://localhost:8000/api/scan/image", json={
    "extracted_text": "your OCR extracted text here",
    "file_name": "my_image.jpg"
})

print(result.json())
```

### Response format:
```json
{
  "action": "REDACT",
  "redacted_text": "My card is [CREDIT CARD] and email is [EMAIL]",
  "risk_score": 0.97,
  "triggered_by": ["layer1_regex"],
  "layers_used": ["regex"],
  "detections": [
    {"type": "credit_card", "values": ["4532 1234 1234 5678"], "source": "regex"}
  ],
  "privacy_note": "100% local â€” no data transmitted"
}
```

---

## ğŸ§ª Run Tests

```bash
# Terminal 1 â€” start server
python main.py

# Terminal 2 â€” run tests
python test_pipeline.py
```

---

## ğŸ¤– ML Model

Model hosted on HuggingFace: `sahana-24/ai-firewall-model`
- Architecture: DistilBERT fine-tuned for sequence classification
- Labels: SAFE (0), PII (1), SENSITIVE (2)
- Auto-downloads on first run â€” no manual setup needed

---

## ğŸ“¦ Requirements

```
fastapi
uvicorn
transformers
torch
google-genai
python-dotenv
huggingface_hub
pydantic
```